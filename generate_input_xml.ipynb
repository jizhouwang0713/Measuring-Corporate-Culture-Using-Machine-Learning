{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/jizhouw0/Desktop/sample_transcripts_xml/20000426-16448-C.xml') as f:\n",
    "    file = f.read()\n",
    "\n",
    "call = BeautifulSoup(file, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-04-26\n",
      "<class 'bs4.element.ResultSet'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# experiment with the meta section\n",
    "date = call.find('date').text\n",
    "print(date)\n",
    "\n",
    "company = call.find_all('company')\n",
    "for c in company: print(type(company), type(c.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Good morning. I am Doug MacMillan, Cambrex Chief Financial Officer. Before we begin, I just want to remind everyone that the meeting is held today under the terms of the Safe Harbor disclaimer. That disclaimer reads as follows: The following discussion may contain certain statements that constitute forward-looking statements within the Securities and Exchange Commission's Safe Harbor provision under the Private Securities Litigation Reform Act and Rule 3B-6 under the Exchange Act. Although such statements represent management's best judgment as of today and that information currently available, such statements involve risks and uncertainties that could cause results to differ materially from the Company's expectations. I would also like to ask everyone to follow a few guidelines. The conference call will be a maximum of one hour and we will begin with business highlights from Jim Mack, Cambrex Chairman and Chief Executive followed by a question-and-answer session. We request that you ask one question at a time, but we will honor a request for one clarification if required. This will allow everyone to ask at least one question. Let me now turn the meeting over to Jim Mack, Cambrex Chairman and Chief Executive Officer. Okay. Thank you, Doug. Welcome everyone. Just for those who may not have seen the press release, I wanted to cover a few highlights from the first quarter before we open it up to Q&A. We had record earnings, up 20% over the first quarter last year and revenue across the entire business was up 9.8%. The Human Health category was up 10% in revenue and would have been 16% increase except for foreign exchange. The Bioscience business was up 43% in revenue. We were also able to increase our gross profit in the Life Science sector, mainly by eliminating low margin products and replacing them with higher margin new products, improved productivity, and new product growth. We have over $25 million of revenue in the budget for new products that are new in the year 2000. And the focus is primarily on proprietary products and services and to a lesser extent some of these do involve service to large pharma. Our repositioning of the Company into life science is proceeding very well. In the quarter, over 83% of the gross profit came from Human Health and Bioscience, up from about 73% last year. In the past year, we completed four acquisitions, all in the life science sector, and all accretive to earnings. Each one of these gives us a new technology platform to build on for the future. We expect there will be a major change in the business model for the way new drug discovery takes place, the way lead compounds are selected and optimized, clinical trials are performed, and resulting in new and different product approvals. This is really going to be driven by the fact that costs for new drug delivery must be reduced by millions â€“ hundreds of millions of dollars and time must be reduced, not by a few months, but by a matter of years. We are involved in this now in a small way and we'll be adding more products and more services in the future to take advantage of this major shift. One example of building for the future that I would like to mention was our acquisition of Chiragene from Celgene two years ago. This is really a new technology platform based on enzyme chemistry. It's an R&D program, but it is being run as a business and in the first two years it costs us a couple of million dollars a year. Now it's beginning to pay off. We developed a new patented route to Taxol Side Chain and have manufactured and shipped several thousand dollars worth of the new compounds. Chiragene has developed a new route for controlled substances used for ADD or attention deficit disorder. We've produced 100 kilogram quantities in the Chiragene cGMP pilot plant and the larger scale production will be at our Charles City, Iowa facility where this business will grow to at least $10 million over the next couple of years. They are also working on chiral compounds at Chiragene, using enzymes to produce a new class of materials called epoxide hydrolase. These will be used to make new chiral building blocks for new drugs. Lastly, I would just like to mention that the demand for active pharmaceutical ingredients for the generic pharmaceutical companies continues to grow and our order backlog is at an all time high. As many of you know, we have the number one position in this field in terms of the number of compounds or active ingredients that are offered, and we expect to add 6-8 new compounds a year going forward. Tracy, we can now open it up for questions.\n"
     ]
    }
   ],
   "source": [
    "# experiment with the management discussion section\n",
    "discussion = call.find('section', {'name': 'MANAGEMENT DISCUSSION SECTION'}).find_all('speaker')\n",
    "# Note that the first sectence is an introduction and is not part of the earnings call\n",
    "# Implementation: we wnat to collect all those sentences somewhere -- not important\n",
    "# print(discussion[0].get('id') is None)\n",
    "\n",
    "full_discussion = \"\"\n",
    "for part in discussion:\n",
    "    if part.get('id') not in (None, '0'):\n",
    "        paragraphs = part.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            full_discussion = full_discussion + \" \" + paragraph.text\n",
    "            \n",
    "print(full_discussion)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory where the transcripts are stored \n",
    "directory = \"C:/Users/jizhouw0/Desktop/sample transcripts\"\n",
    "\n",
    "# define a helper function -- line_counter\n",
    "def line_counter(a_file):\n",
    "    \"\"\"Count the number of lines in a text file\n",
    "    \n",
    "    Arguments:\n",
    "        a_file {str or Path} -- input text file\n",
    "    \n",
    "    Returns:\n",
    "        int -- number of lines in the file\n",
    "    \"\"\"\n",
    "    n_lines = 0\n",
    "    with open(a_file, \"rb\") as f:\n",
    "        n_lines = sum(1 for _ in f)\n",
    "    return n_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n",
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n",
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n",
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n",
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n",
      "transcriptid\n",
      "keydevid\n",
      "companyid\n",
      "companyname\n",
      "headline\n",
      "transcriptcreationdate\n",
      "mostimportantdate\n",
      "components\n",
      "full_transcript_text\n"
     ]
    }
   ],
   "source": [
    "# This is just a block of junk code to facilitate the visual inspection of data\n",
    "\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        with open(filename.path) as f:\n",
    "            trspt = json.load(f)\n",
    "            components = trspt[\"components\"]\n",
    "            for j in trspt.keys():\n",
    "                print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We iteratre over all the transripts (in json format) and generate three text files as inout for the ML algorithm \n",
    "# scripted section, Q & A section, and both\n",
    "text_scripted, text_unscripted, text_both = \"\", \"\", \"\"\n",
    "id2firms = {\"document_id\":[], \"firm_id\": [], \"time\": [], \"firm_name\": []}\n",
    "doc_count = 0\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        doc_count += 1 # counts the number of documents\n",
    "        with open(filename.path) as f:\n",
    "            trspt = json.load(f)\n",
    "            id2firms[\"document_id\"].append(trspt[\"transcriptid\"])\n",
    "            id2firms[\"firm_id\"].append(trspt[\"companyid\"])\n",
    "            id2firms[\"time\"].append(trspt[\"transcriptcreationdate\"])\n",
    "            id2firms[\"firm_name\"].append(trspt[\"companyname\"])\n",
    "            \n",
    "            components = trspt[\"components\"]\n",
    "            \n",
    "            str_list_both = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] != \"Presentation Operator Message\"]\n",
    "            text_both = text_both + '\\n' + \"\".join(str_list_both).replace('\\r', '').replace('\\n', '')\n",
    "            \n",
    "            str_list_unscripted = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] != \"Presentation Operator Message\" if components[i][\"componenttypename\"] != \"Presenter Speech\"]\n",
    "            text_unscripted = text_unscripted + '\\n' + \"\".join(str_list_unscripted).replace('\\r', '').replace('\\n', '')\n",
    "            \n",
    "            str_list_scripted = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] == \"Presenter Speech\"]\n",
    "            text_scripted = text_scripted + '\\n' + \"\".join(str_list_scripted).replace('\\r', '').replace('\\n', '')\n",
    "            \n",
    "with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt', 'w') as f: \n",
    "    f.write(text_both.replace(\"\\n\",\"\",1))\n",
    "    \n",
    "with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_unscripted.txt', 'w') as f: \n",
    "    f.write(text_unscripted.replace(\"\\n\",\"\",1))\n",
    "\n",
    "with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_scripted.txt', 'w') as f: \n",
    "    f.write(text_scripted.replace(\"\\n\",\"\",1))\n",
    "    \n",
    "document_id = map(str, id2firms[\"document_id\"])\n",
    "with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/document_ids.txt', 'w') as f: \n",
    "    f.write('\\n'.join(document_id))\n",
    "    \n",
    "df_id2firms = pd.DataFrame(data=id2firms)\n",
    "df_id2firms.to_csv(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/id2firms.csv\", header = True, index = False)\n",
    "    \n",
    "assert line_counter(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt\") == doc_count, \"Line Number Differs From Document Count!\"\n",
    "assert df_id2firms.shape[0] == line_counter(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt\"), \"Number of IDs Differs From Number of Documents!\"\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We iteratre over all the transripts (in json format) and generate three text files as inout for the ML algorithm \n",
    "# scripted section, Q & A section, and both\n",
    "text_scripted, text_unscripted, text_both = \"\", \"\", \"\"\n",
    "id2firms = {\"document_id\":[], \"firm_id\": [], \"time\": [], \"firm_name\": []}\n",
    "doc_count = 0\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        doc_count += 1 # counts the number of documents\n",
    "        with open(filename.path) as f:\n",
    "            trspt = json.load(f)\n",
    "        id2firms[\"document_id\"].append(trspt[\"transcriptid\"])\n",
    "        id2firms[\"firm_id\"].append(trspt[\"companyid\"])\n",
    "        id2firms[\"time\"].append(trspt[\"transcriptcreationdate\"])\n",
    "        id2firms[\"firm_name\"].append(trspt[\"companyname\"])\n",
    "            \n",
    "        components = trspt[\"components\"]\n",
    "            \n",
    "        str_list_both = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] != \"Presentation Operator Message\"]\n",
    "        with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt', 'a') as out_f: \n",
    "            out_f.write(\"\".join(str_list_both).replace('\\r', '').replace('\\n', '')) if doc_count == 0 else out_f.write(\"\".join(str_list_both).replace('\\r', '').replace('\\n', '') + '\\n')\n",
    "            \n",
    "        str_list_unscripted = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] != \"Presentation Operator Message\" if components[i][\"componenttypename\"] != \"Presenter Speech\"]\n",
    "        with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_unscripted.txt', 'a') as out_f: \n",
    "            out_f.write(\"\".join(str_list_unscripted).replace('\\r', '').replace('\\n', '')) if doc_count == 0 else out_f.write(\"\".join(str_list_unscripted).replace('\\r', '').replace('\\n', '') + '\\n')\n",
    "            \n",
    "            \n",
    "        str_list_scripted = [components[i][\"text\"] for i in range(len(components)) if components[i][\"componenttypename\"] == \"Presenter Speech\"]\n",
    "        with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_scripted.txt', 'a') as out_f: \n",
    "            out_f.write(\"\".join(str_list_scripted).replace('\\r', '').replace('\\n', '')) if doc_count == 0 else out_f.write(\"\".join(str_list_scripted).replace('\\r', '').replace('\\n', '') + '\\n')\n",
    "\n",
    "document_id = map(str, id2firms[\"document_id\"])\n",
    "id2firms[\"firm_id\"] = map(str, id2firms[\"firm_id\"])\n",
    "with open('C:/Users/jizhouw0/Desktop/sample transcripts/text_all/document_ids.txt', 'w') as f: \n",
    "    f.write('\\n'.join(document_id))\n",
    "    \n",
    "df_id2firms = pd.DataFrame(data=id2firms)\n",
    "df_id2firms[[\"document_id\", \"firm_id\"]] = df_id2firms[[\"document_id\", \"firm_id\"]].astype(str)\n",
    "df_id2firms.to_csv(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/id2firms.csv\", header = True, index = False)\n",
    "    \n",
    "assert line_counter(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt\") == doc_count, \"Line Number Differs From Document Count!\"\n",
    "assert df_id2firms.shape[0] == line_counter(\"C:/Users/jizhouw0/Desktop/sample transcripts/text_all/transcripts_both.txt\"), \"Number of IDs Differs From Number of Documents!\"\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "352bbe8eef13dbc790a4a10aef27629e00f277446254fc1e3e762725b62d7e10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
